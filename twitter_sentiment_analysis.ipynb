{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d86b2dc",
   "metadata": {},
   "source": [
    "# *TWITTER SENTIMENT ANALYSIS*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2b566",
   "metadata": {},
   "source": [
    "**Problem Statement**\n",
    "\n",
    "The objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\n",
    "\n",
    "Formally, given a training sample of tweets and labels, where label '1' denotes the tweet is racist/sexist and label '0' denotes the tweet is not racist/sexist, your objective is to predict the labels on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe4aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For handling data\n",
    "import pandas as pd\n",
    "\n",
    "# For numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Library for pattern matching\n",
    "import re\n",
    "\n",
    "# For NLP related tasks\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef683c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf3143",
   "metadata": {},
   "source": [
    "<font size=3>**Steps to Follow:**</font>\n",
    "1. Loading and Exploring Data\n",
    "2. Text Cleaning\n",
    "3. Data Preparation\n",
    "    1. Label Encoding\n",
    "    2. Split Data\n",
    "    3. Feature Engineering using TF-IDF\n",
    "4. Model Building\n",
    "    1. Naive Bayes\n",
    "    2. Logistic Regression\n",
    "    3. Model Building Summary\n",
    "5. Final Sentiment Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaeb5d",
   "metadata": {},
   "source": [
    "### Loading and Exploring Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c7827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape => (31962, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read CSV file\n",
    "df_train = pd.read_csv(r\"C:\\Users\\TheWhiteWolf\\NLP\\Module1\\Projects\\Twitter_Sentiment_Analysis\\train.csv\")\n",
    "\n",
    "# Shape of the dataframe\n",
    "print(\"Shape =>\", df_train.shape)\n",
    "\n",
    "# first first five rows\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d13d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7848      @user so   that @user is presenting âcurves...\n",
       "29488    not the first or the last. #yyc    the tax bil...\n",
       "9494     removal of #aap spokesperson #alkalamba showca...\n",
       "20604    my trust fund check is gonna be so bomb. ðð...\n",
       "9290     idk what its like to feel loved. #depressed   ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some sample tweets\n",
    "df_train['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7b8844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution\n",
    "# Where label '1' denotes the tweet is racist/sexist and label '0' denotes the tweet is not racist/sexist\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528802c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    92.98542\n",
       "1     7.01458\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution in percentage\n",
    "# Where label '1' denotes the tweet is racist/sexist and label '0' denotes the tweet is not racist/sexist\n",
    "df_train['label'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d9b5a",
   "metadata": {},
   "source": [
    "### Loading and Exploring Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4a3bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape => (17197, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read CSV file\n",
    "df_test = pd.read_csv(r\"C:\\Users\\TheWhiteWolf\\NLP\\Module1\\Projects\\Twitter_Sentiment_Analysis\\test.csv\")\n",
    "\n",
    "# Shape of the dataframe\n",
    "print(\"Shape =>\", df_test.shape)\n",
    "\n",
    "# first first five rows\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8072c4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9290    let's make it #today â¤ï¸  #bradpitt #celeb ...\n",
       "3741    i have some good friends ð   #friends #tram...\n",
       "7148    wanna go shopping but i have $0.17 in my accou...\n",
       "6720    very   abt what happened in #orlando we #must ...\n",
       "2872    new #trending #gif on @user  , euro 2016, euro...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some sample tweets\n",
    "df_test['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c727d",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba44160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for text cleaninig\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # remove user mentions\n",
    "    text = re.sub(r'@[a-zA-Z0-9]+', '', text)\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # converting text to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Fetch only words\n",
    "    text = re.sub('[^a-z]', ' ', text)\n",
    "    \n",
    "    # Removing extra spaces\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    \n",
    "    # Creating doc object\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize the text\n",
    "    tokens = [token.lemma_ for token in doc if (token.is_stop == False)]\n",
    "    \n",
    "    # Join tokens by space\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebc00a",
   "metadata": {},
   "source": [
    "#### Perform text cleaning on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41bbe18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform text cleaning\n",
    "df_train['cleaned_tweet'] = df_train['tweet'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92328725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank lyft credit t use cause don t offer wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love u u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @user when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0    father dysfunctional selfish drag kid dysfun...  \n",
       "1    thank lyft credit t use cause don t offer wh...  \n",
       "2                                     bihday majesty  \n",
       "3                             model love u u time ur  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['tweet','cleaned_tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb1fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned tweets and labels to variable\n",
    "tweets = df_train['cleaned_tweet'].values\n",
    "labels = df_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e792cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['  father dysfunctional selfish drag kid dysfunction run',\n",
       "       '  thank lyft credit t use cause don t offer wheelchair van pdx disapointe getthanke',\n",
       "       '  bihday majesty', '  model love u u time ur',\n",
       "       '  factsguide society motivation',\n",
       "       '  huge fan fare big talking leave chaos pay dispute allshowandnogo',\n",
       "       '  camping tomorrow danny',\n",
       "       'school year year exam t think school exam hate imagine actorslife revolutionschool girl',\n",
       "       'win love land allin cavs champions cleveland clevelandcavalier',\n",
       "       '  welcome m s gr'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample cleaned tweet\n",
    "tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fed10805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample labels\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d3438",
   "metadata": {},
   "source": [
    "#### Perform text cleaning on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f91e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform text cleaning\n",
    "df_test['cleaned_tweet'] = df_test['tweet'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7db53aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife aislife require passion dedicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white supremacist want new bird movie s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe way heal acne altwaystoheal healthy healing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>hp cursed child book reservation yes harrypott...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd bihday amazing hilarious nephew eli ahmir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  #studiolife #aislife #requires #passion #dedic...   \n",
       "1   @user #white #supremacists want everyone to s...   \n",
       "2  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0    studiolife aislife require passion dedicatio...  \n",
       "1            white supremacist want new bird movie s  \n",
       "2   safe way heal acne altwaystoheal healthy healing  \n",
       "3  hp cursed child book reservation yes harrypott...  \n",
       "4    rd bihday amazing hilarious nephew eli ahmir...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['tweet','cleaned_tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "306b945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned tweets to variable\n",
    "tweets_test = df_test['cleaned_tweet'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0320545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['  studiolife aislife require passion dedication willpower find newmaterial',\n",
       "       '  white supremacist want new bird movie s',\n",
       "       'safe way heal acne altwaystoheal healthy healing',\n",
       "       'hp cursed child book reservation yes harrypotter pottermore favorite',\n",
       "       '  rd bihday amazing hilarious nephew eli ahmir uncle dave love miss',\n",
       "       'choose momtip',\n",
       "       'inside die eye ness smokeyeye tired lonely sof grunge',\n",
       "       '  finished tattoo ink ink loveit thank aleeee',\n",
       "       '  understand dad leave young deep inthefeel',\n",
       "       '  delicious food lovelife capetown mannaepicure resturant'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample cleaned tweet\n",
    "tweets_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9257be",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f00f62",
   "metadata": {},
   "source": [
    "### *Feature Engineering using TF-IDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8999e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383a4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize TFIDF\n",
    "word_vectorizer = TfidfVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e1271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Vectorizer on Train set\n",
    "word_vectorizer.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2bd5cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31962x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 131106 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TF-IDF vectors for Train Set\n",
    "train_word_features = word_vectorizer.transform(tweets)\n",
    "train_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9f17380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=1000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Vectorizer on Test set\n",
    "word_vectorizer.fit(tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3466514c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17197x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 70469 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TF-IDF vectors for Test Set\n",
    "test_word_features = word_vectorizer.transform(tweets_test)\n",
    "test_word_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501c281",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768008c",
   "metadata": {},
   "source": [
    "### *Naive Bayes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f01e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing for modelling\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61bf7a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Train model\n",
    "nb_model = MultinomialNB().fit(train_word_features, labels)\n",
    "nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdf346b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for train set\n",
    "train_pred_nb = nb_model.predict(train_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95cf9ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08053ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Train Set: 0.9366703984293401\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on Training Set\n",
    "print('F1-score on Train Set:', f1_score(labels, train_pred_nb, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e1be8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for test set\n",
    "test_pred_nb = nb_model.predict(test_word_features)\n",
    "test_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42163d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on Training Set\n",
    "#print('F1-score on Train Set:', f1_score(labels, test_pred_nb, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254640d",
   "metadata": {},
   "source": [
    "### *Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bcd30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c0a5dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "lr_model=LogisticRegression(solver='liblinear').fit(train_word_features,labels)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25900807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for train set\n",
    "train_pred_lr = lr_model.predict(train_word_features)\n",
    "train_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03a799eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Train Set: 0.9433698601551692\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on Training Set\n",
    "print(\"F1-score on Train Set:\",f1_score(labels,train_pred_lr,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef6ad916",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_lr = lr_model.predict(test_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d77973f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "858797b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = test_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54af254d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17059\n",
       "1      138\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad7001e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99.197534\n",
       "1     0.802466\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4a0e9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studiolife aislife require passion dedicatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white supremacist want new bird movie s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe way heal acne altwaystoheal healthy healing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hp cursed child book reservation yes harrypott...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rd bihday amazing hilarious nephew eli ahmir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>think factory leave right polarisation trump u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>feel like mermaid hairflip neverready formal w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>hillary campaign today ohio omg amp word lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>happy work conference right mindset lead cultu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>song glad free download shoegaze newmusic newsong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_tweet  label\n",
       "0        studiolife aislife require passion dedicatio...      0\n",
       "1                white supremacist want new bird movie s      0\n",
       "2       safe way heal acne altwaystoheal healthy healing      0\n",
       "3      hp cursed child book reservation yes harrypott...      0\n",
       "4        rd bihday amazing hilarious nephew eli ahmir...      0\n",
       "...                                                  ...    ...\n",
       "17192  think factory leave right polarisation trump u...      0\n",
       "17193  feel like mermaid hairflip neverready formal w...      0\n",
       "17194    hillary campaign today ohio omg amp word lik...      0\n",
       "17195  happy work conference right mindset lead cultu...      0\n",
       "17196  song glad free download shoegaze newmusic newsong      0\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['cleaned_tweet','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "302dcb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>suppo taiji fisherman bully racism tweet taiji...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>happy instagram instagood instagram instapassp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>wish kpop aist come country win t able perform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>nice ready come oakland marijuana business boo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>s sad guy kill warrior team soon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_tweet  label\n",
       "33   suppo taiji fisherman bully racism tweet taiji...      1\n",
       "189  happy instagram instagood instagram instapassp...      1\n",
       "294  wish kpop aist come country win t able perform...      1\n",
       "419  nice ready come oakland marijuana business boo...      1\n",
       "433                   s sad guy kill warrior team soon      1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['cleaned_tweet','label']][df_test['label'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a505b3b",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n",
    "Hate speech is an unfortunately common occurrence on the  Internet.  Often social media sites like Facebook and Twitter face the problem of identifying and censoring problematic posts while weighing the right to freedom of speech. The importance of detecting and moderating hate speech is evident from the strong connection between hate speech and actual hate crimes. Early identification of users promoting hate speech could enable outreach programs that attempt to prevent an escalation from speech to action. Sites such as Twitter and Facebook have been seeking to actively combat hate speech. Despite these reasons, NLP research on hate speech has been very limited, primarily due to the lack of a general definition of hate speech, an analysis of its demographic influences, and an investigation of the most effective features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fef47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
